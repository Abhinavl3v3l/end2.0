{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 4 Quiz.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinavl3v3l/end2.0/blob/main/Session_4_Quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Od33G73EarN",
        "outputId": "e273ec22-f172-4406-b5a9-53e513d50dd5"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS\n",
            "To: /content/text.txt\n",
            "\r  0% 0.00/10.3k [00:00<?, ?B/s]\r100% 10.3k/10.3k [00:00<00:00, 23.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b4af73-9d9c-471d-ab80-4aa39952bac9"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1-y) # as per code below\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y ** 2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUjOxus-IHeP"
      },
      "source": [
        "# Quiz Question 1\n",
        "What is the value of sigmoid(0) calculated from your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx3XmF8-IFt-",
        "outputId": "3b6f51c4-f00b-4fdc-ea16-cf9ff79404e3"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luJHYNVfIZ1Z"
      },
      "source": [
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66QFG3KrIoLg",
        "outputId": "46eddf51-4e2e-4ab9-d7db-842cdb9d6e7f"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q31DMsA3IaVV"
      },
      "source": [
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fYuPPgsI0iF",
        "outputId": "3951a1bd-1ac7-4b99-b919-aec7d716f7bc"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFnEi6bwIadJ"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkxSCNLUI8tU",
        "outputId": "bf2a2f2d-8a6c-44b7-ee15-dec422eae2a4"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size# write your code here\n",
        "size_b = z_size# write your code here\n",
        "size_c = X_size# write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v) # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v) # write your code here\n",
        "\n",
        "    C = f * C_prev + i * C_bar# write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)# write your code here\n",
        "    h = o * tanh(C)# write your code here\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzwXyeuGK860",
        "outputId": "5849854f-6b33-4dec-c562-8947c0227907"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB1dj3BfLKBy",
        "outputId": "4dd3b676-c233-49c1-d1d0-1eebcf24e96c"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Put3AsEbLNbK",
        "outputId": "e190b0e1-b5df-40f7-918c-547290d98715"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSa_DIOgLSfv",
        "outputId": "152dcad2-013b-48b7-ee13-9fb02566e635"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "f567b66b-0313-4fdf-ca73-1ac32e9bfd72"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " ses upper get their symptoms, such a fluids and pain relion in Wuhana, in hes Saugios. Anyon inpecpied om coronavirus is tating a cenver.\n",
            "\n",
            "Is to inerets mendaterr and scraecan Ceing infections China,  \n",
            "----\n",
            "iter 49900, loss 3.940102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}